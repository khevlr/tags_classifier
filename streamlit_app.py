import streamlit as st
from newspaper import Article
import torch
import joblib
from transformers import AutoModelForSequenceClassification, AutoTokenizer
import pickle
import requests
from bs4 import BeautifulSoup
import time


model_path = "nurkz_bert"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path)


with open('label_binarizer.pkl', 'rb') as f:
    classes = pickle.load(f)

def predict_tags(text, threshold=0.2):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    inputs = {key: torch.tensor(val) for key, val in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.sigmoid(outputs.logits).numpy()[0]

    predicted_tags = [classes[i] for i, p in enumerate(probs) if p >= threshold]
    return predicted_tags

def get_text_tags(url, retries=3, delay=5):

    headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
            "Accept-Language": "en-US,en;q=0.9",
            }

    try:

        r = requests.get(url, timeout=(3,5), headers=headers)

        r.raise_for_status()

    except requests.exceptions.Timeout:

        print(f"Timeout –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {url}")
        
        if retries > 0:
            print(f"–ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {delay} —Å–µ–∫... –û—Å—Ç–∞–ª–æ—Å—å –ø–æ–ø—ã—Ç–æ–∫: {retries}")
            time.sleep(delay)
            return get_text_tags(url, retries - 1, delay)
        else:
            return "", []
    
    except requests.exceptions.RequestException as e:

        print(f"Error downloading {url}: {e}")
        return "", []
    
    soup = BeautifulSoup(r.text, 'html.parser')
    
    paragraphs = soup.select('p.formatted-body__paragraph')

    article_text = ''''''

    for p in paragraphs:

        for el in p.find_all(['a', 'img', 'em', 'strong', 'span']):
            el.replace_with(f''' {el.get_text(strip=True)}''')

        text = p.get_text()

        if text:
            article_text += f''' {text}'''

    return article_text
    
st.title("üì∞ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–µ–≥–æ–≤ –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ nur.kz")
option = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–± –≤–≤–æ–¥–∞:", ("–¢–µ–∫—Å—Ç –≤—Ä—É—á–Ω—É—é", "–°—Å—ã–ª–∫–∞ –Ω–∞ —Å—Ç–∞—Ç—å—é"))

text_input = ""
if option == "–¢–µ–∫—Å—Ç –≤—Ä—É—á–Ω—É—é":
    text_input = st.text_area("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏:", height=300)
elif option == "–°—Å—ã–ª–∫–∞ –Ω–∞ —Å—Ç–∞—Ç—å—é":
    url = st.text_input("–í–≤–µ–¥–∏—Ç–µ URL —Å—Ç–∞—Ç—å–∏:")
    if url:
        text_input = get_text_tags(url)
        st.text_area("–ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏:", text_input, height=300)

if st.button("–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Ç–µ–≥–∏") and text_input.strip():
    tags = predict_tags(text_input)
    st.subheader("üè∑Ô∏è –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ —Ç–µ–≥–∏:")
    if tags:
        st.write(", ".join(tags))
    else:
        st.write("–¢–µ–≥–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã (–≤–æ–∑–º–æ–∂–Ω–æ, –º–æ–¥–µ–ª—å –Ω–µ —É–≤–µ—Ä–µ–Ω–∞).")


